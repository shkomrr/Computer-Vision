{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97984,"databundleVersionId":14096757,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"f34f6fc0","cell_type":"markdown","source":"# üè• ECG Digitization - Training & Calibration\n\n**Purpose:** Analyze training data to create calibration parameters\n\n**Outputs:**\n- `ecg_config.json` - Calibration parameters\n- Analysis of optimal settings for signal extraction\n\n**Upload outputs as Kaggle Dataset** for use in inference notebook","metadata":{}},{"id":"790774c2","cell_type":"code","source":"# Imports\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport os\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport json\nfrom scipy.ndimage import gaussian_filter1d\nfrom scipy import interpolate\n\nprint(\"üèãÔ∏è ECG Training Mode - Calibration\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T15:44:29.277321Z","iopub.execute_input":"2026-01-14T15:44:29.277575Z","iopub.status.idle":"2026-01-14T15:44:30.684423Z","shell.execute_reply.started":"2026-01-14T15:44:29.277553Z","shell.execute_reply":"2026-01-14T15:44:30.683419Z"}},"outputs":[{"name":"stdout","text":"üèãÔ∏è ECG Training Mode - Calibration\n============================================================\n","output_type":"stream"}],"execution_count":1},{"id":"c6a02c46","cell_type":"code","source":"# Set paths\nIS_KAGGLE = os.path.exists('/kaggle/input')\n\nif IS_KAGGLE:\n    DATA_PATH = Path(\"../input/physionet-ecg-image-digitization/\")\nelse:\n    possible_paths = [\n        Path(\"./data/physionet-ecg-image-digitization/\"),\n        Path(\"./physionet-ecg-image-digitization/\"),\n        Path(\"../data/physionet-ecg-image-digitization/\"),\n    ]\n    DATA_PATH = None\n    for p in possible_paths:\n        if p.exists():\n            DATA_PATH = p\n            break\n    if DATA_PATH is None:\n        DATA_PATH = Path(\"./data/\")\n\nTRAIN_PATH = DATA_PATH / \"train\"\nOUTPUT_DIR = Path(\"./output\")\nOUTPUT_DIR.mkdir(exist_ok=True)\n\nprint(f\"Data path: {DATA_PATH}\")\nprint(f\"Train path: {TRAIN_PATH}\")\nprint(f\"Output dir: {OUTPUT_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T15:44:30.686679Z","iopub.execute_input":"2026-01-14T15:44:30.687107Z","iopub.status.idle":"2026-01-14T15:44:30.696457Z","shell.execute_reply.started":"2026-01-14T15:44:30.687083Z","shell.execute_reply":"2026-01-14T15:44:30.695267Z"}},"outputs":[{"name":"stdout","text":"Data path: ../input/physionet-ecg-image-digitization\nTrain path: ../input/physionet-ecg-image-digitization/train\nOutput dir: output\n","output_type":"stream"}],"execution_count":2},{"id":"9b4e7a6c","cell_type":"code","source":"# Load training metadata\ntrain_meta = pd.read_csv(DATA_PATH / \"train.csv\")\nprint(f\"Training records: {train_meta['id'].nunique()}\")\nprint(f\"Total signals: {len(train_meta)}\")\nprint(f\"\\nSample:\")\nprint(train_meta.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T15:44:30.697561Z","iopub.execute_input":"2026-01-14T15:44:30.697845Z","iopub.status.idle":"2026-01-14T15:44:30.760107Z","shell.execute_reply.started":"2026-01-14T15:44:30.697823Z","shell.execute_reply":"2026-01-14T15:44:30.759132Z"}},"outputs":[{"name":"stdout","text":"Training records: 977\nTotal signals: 977\n\nSample:\n         id    fs  sig_len\n0   7663343   500     5000\n1  10140238  1000    10000\n2  11842146  1000    10000\n3  19030958   250     2500\n4  19585145   512     5120\n","output_type":"stream"}],"execution_count":3},{"id":"808aac95","cell_type":"code","source":"# Analyze image statistics\nprint(\"üìä Analyzing training images...\\n\")\n\nimage_stats = []\nsample_records = train_meta['id'].unique()[:10]  # Sample 10 images\n\nfor record_id in tqdm(sample_records, desc=\"Analyzing images\"):\n    record_id_str = str(record_id)\n    img_path = TRAIN_PATH / f\"{record_id_str}.png\"\n    \n    if not img_path.exists():\n        img_path = TRAIN_PATH / record_id_str / f\"{record_id_str}.png\"\n    \n    if img_path.exists():\n        img = cv2.imread(str(img_path))\n        if img is not None:\n            h, w = img.shape[:2]\n            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n            \n            image_stats.append({\n                'record_id': record_id,\n                'height': h,\n                'width': w,\n                'mean_brightness': gray.mean(),\n                'std_brightness': gray.std()\n            })\n\nstats_df = pd.DataFrame(image_stats)\nprint(\"\\nImage statistics:\")\nprint(stats_df.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T15:44:30.761098Z","iopub.execute_input":"2026-01-14T15:44:30.761360Z","iopub.status.idle":"2026-01-14T15:44:30.971684Z","shell.execute_reply.started":"2026-01-14T15:44:30.761336Z","shell.execute_reply":"2026-01-14T15:44:30.970342Z"}},"outputs":[{"name":"stdout","text":"üìä Analyzing training images...\n\n","output_type":"stream"},{"name":"stderr","text":"Analyzing images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 156.51it/s]","output_type":"stream"},{"name":"stdout","text":"\nImage statistics:\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/421885085.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mstats_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nImage statistics:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(self, percentiles, include, exclude)\u001b[0m\n\u001b[1;32m  11974\u001b[0m         \u001b[0mmax\u001b[0m            \u001b[0mNaN\u001b[0m      \u001b[0;36m3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11975\u001b[0m         \"\"\"\n\u001b[0;32m> 11976\u001b[0;31m         return describe_ndframe(\n\u001b[0m\u001b[1;32m  11977\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11978\u001b[0m             \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/methods/describe.py\u001b[0m in \u001b[0;36mdescribe_ndframe\u001b[0;34m(obj, include, exclude, percentiles)\u001b[0m\n\u001b[1;32m     89\u001b[0m         )\n\u001b[1;32m     90\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         describer = DataFrameDescriber(\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/methods/describe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot describe a DataFrame without columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Cannot describe a DataFrame without columns"],"ename":"ValueError","evalue":"Cannot describe a DataFrame without columns","output_type":"error"}],"execution_count":4},{"id":"7eb93fd2","cell_type":"code","source":"# Analyze sampling rates\nprint(\"\\nüìà Analyzing sampling rates...\\n\")\n\nfs_stats = train_meta.groupby('lead')['fs'].agg(['mean', 'min', 'max', 'std'])\nprint(fs_stats)\n\nrows_stats = train_meta.groupby('lead')['number_of_rows'].agg(['mean', 'min', 'max', 'std'])\nprint(\"\\nRows per lead:\")\nprint(rows_stats)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T15:44:30.972523Z","iopub.status.idle":"2026-01-14T15:44:30.972944Z","shell.execute_reply.started":"2026-01-14T15:44:30.972721Z","shell.execute_reply":"2026-01-14T15:44:30.972739Z"}},"outputs":[],"execution_count":null},{"id":"6b5c165c","cell_type":"code","source":"# Create optimal configuration based on analysis\nconfig = {\n    # Image processing parameters\n    \"threshold_value\": 50,\n    \"gaussian_sigma\": 1.0,\n    \"grid_layout\": {\"rows\": 3, \"cols\": 4},\n    \n    # Signal extraction\n    \"voltage_range\": [-2.0, 2.0],\n    \"interpolation_method\": \"cubic\",\n    \n    # Lead configuration\n    \"lead_names\": [\"I\", \"II\", \"III\", \"aVR\", \"aVL\", \"aVF\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"],\n    \n    # Typical sampling rates (from analysis)\n    \"typical_fs\": int(train_meta['fs'].median()),\n    \n    # Image statistics\n    \"avg_image_height\": int(stats_df['height'].mean()) if len(stats_df) > 0 else 800,\n    \"avg_image_width\": int(stats_df['width'].mean()) if len(stats_df) > 0 else 1200,\n    \n    # Version\n    \"version\": \"1.0\",\n    \"method\": \"computer_vision_extraction\"\n}\n\nprint(\"\\n‚öôÔ∏è Configuration created:\")\nfor key, value in config.items():\n    print(f\"   {key}: {value}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"30f967d7","cell_type":"code","source":"# Save configuration\nconfig_path = OUTPUT_DIR / \"ecg_config.json\"\nwith open(config_path, 'w') as f:\n    json.dump(config, f, indent=2)\n\nprint(f\"\\nüíæ Configuration saved to: {config_path}\")\nprint(\"\\nüì¶ Upload this to Kaggle as a dataset:\")\nprint(\"   1. Create new dataset on Kaggle\")\nprint(\"   2. Upload ecg_config.json\")\nprint(\"   3. Name it: ecg-trained-config\")\nprint(\"   4. Use in inference notebook\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f8bb9a7b","cell_type":"code","source":"# Visualize sample ECG\nif len(sample_records) > 0:\n    sample_id = sample_records[0]\n    img_path = TRAIN_PATH / f\"{sample_id}.png\"\n    \n    if not img_path.exists():\n        img_path = TRAIN_PATH / str(sample_id) / f\"{sample_id}.png\"\n    \n    if img_path.exists():\n        img = cv2.imread(str(img_path))\n        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        plt.figure(figsize=(15, 8))\n        plt.imshow(img_rgb)\n        plt.title(f'Sample ECG Image - Record {sample_id}')\n        plt.axis('off')\n        plt.tight_layout()\n        plt.savefig(OUTPUT_DIR / 'sample_ecg.png', dpi=150, bbox_inches='tight')\n        plt.show()\n        \n        print(f\"\\nüì∏ Sample visualization saved to: {OUTPUT_DIR / 'sample_ecg.png'}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6b96744c","cell_type":"code","source":"# Summary\nprint(\"\\n\" + \"=\"*60)\nprint(\"‚úÖ Training/Calibration Complete!\")\nprint(\"=\"*60)\nprint(f\"\\nüìÅ Output files in: {OUTPUT_DIR}\")\nprint(f\"   - ecg_config.json (upload to Kaggle)\")\nprint(f\"   - sample_ecg.png (visualization)\")\nprint(\"\\nüîÑ Next steps:\")\nprint(\"   1. Upload output files as Kaggle dataset\")\nprint(\"   2. Use inference notebook for submission\")\nprint(\"   3. Add dataset to inference notebook inputs\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}